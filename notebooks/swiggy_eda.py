# -*- coding: utf-8 -*-
"""Swiggy_EDA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WUQgcscoGGEnca3-vJjsKRhN4VC2MY7u
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.gridspec import GridSpec
import seaborn as sns
from scipy.stats import chi2_contingency, f_oneway, jarque_bera, probplot
import plotly.express as px

"""## Load data"""

# Loading the cleaned data
Data = pd.read_csv('/content/Swiggy_cleaned_data.csv')

Data.head()

Data.shape

"""## Primary analysis"""

Data.isnull().sum()

# No. of missing values in rows of the data
missing_rows = Data.isnull().any(axis = 1).sum()

print(f"There are {missing_rows} rows with missing values in the data.")
print(f"The percentage of missing values in data are {(missing_rows / Data.shape[0]) * 100:.2f}%.")

"""**The initial percentage of missing data was around `9.2%` and increased to `16.35%` because we transformed 0 values in the latitude & longitude columns to NaN.**"""

# Check for duplicated values in data
print(Data.duplicated().sum())

# Data types
Data.dtypes

# Seperate the numerical and categorical columns from the data
Num_cols = Data.columns[[1,2,3,4,5,6,16,22,25]].tolist()
Cat_cols = [col for col in Data.columns.tolist() if col not in Num_cols]

print(f"There are ({len(Num_cols)}) numerical columns and ({len(Cat_cols)}) categorical columns from the data.")

Num_cols

Cat_cols

# Statistical summary (Numerical columns)
Data[Num_cols].describe()

# Statistical summary (Categorical columns)
Data.assign(**{col: Data[col].astype("object") for col in Cat_cols}).describe(include = "object").T



"""## Missing values analysis"""

import missingno as msno

"""### Matrix plot"""

msno.matrix(Data)

"""### Bar plot"""

msno.bar(Data)

"""### Heatmap"""

msno.heatmap(Data)

"""### Dendrogram"""

msno.dendrogram(Data)



"""## Functions to perform EDA"""

# -------------------- Univariate analysis (Numercial columns) ----------------------
def numerical_analysis(dataframe, column_name, cat_col = None, bins = "auto"):
  # create the figure
  fig = plt.figure(figsize = (15,10))

  # generate the layout
  grid = GridSpec(nrows = 2, ncols = 2, figure = fig)

  # set subplots
  ax1 = fig.add_subplot(grid[0, 0])
  ax2 = fig.add_subplot(grid[0, 1])
  ax3 = fig.add_subplot(grid[1, :])

  # plot the kdeplot
  sns.kdeplot(dataframe, x = column_name, hue = cat_col, ax = ax1)

  # plot the boxplot
  sns.boxplot(dataframe, x = column_name, hue = cat_col, ax = ax2)

  # plot the histogram
  sns.histplot(dataframe, x = column_name, bins = bins, hue = cat_col, kde = True, ax = ax3)

  plt.tight_layout()
  plt.show()


# ---------------------- Univariate analysis (Categorical column) ----------------------
def categorical_analysis(dataframe, column_name):
  # print the values counts of categories
  cat_analysis = pd.DataFrame({
      "Count": dataframe[column_name].value_counts(),
      "Percentage": (
        dataframe[column_name]
        .value_counts(normalize=True)
        .mul(100)
        .round(2)
        .astype(str)
        .add("%")
    )
  })

  display(cat_analysis)
  print("*" * 50)

  # get unique categories
  unique_categories = dataframe[column_name].unique().tolist()
  number_of_categoris = dataframe[column_name].nunique()
  print(f"The unique categories in {column_name} column are {unique_categories}")
  print("*" * 50)
  print(f"The number of categories in {column_name} column are {number_of_categoris}")

  # Plot the countplot
  sns.countplot(dataframe, x = column_name)
  plt.xticks(rotation = 45)
  plt.show()




# -------------------- Bivariate analysis (Both) --------------------------
def numerical_categorical_analysis(dataframe, cat_column_1, num_column):
  fig, (ax1, ax2) = plt.subplots(2, 2, figsize = (15, 7.5))

  # plot the barplor
  sns.barplot(dataframe, x = cat_column_1, y  = num_column, ax = ax1[0])

  # plot the boxplot
  sns.boxplot(dataframe, x = cat_column_1, y = num_column, ax = ax1[1])

  # plot the violin plot
  sns.violinplot(dataframe, x = cat_column_1, y = num_column, ax = ax2[0])

  # plot the strip plot
  sns.stripplot(dataframe, x = cat_column_1, y = num_column, ax = ax2[1])

  plt.tight_layout()
  plt.show()



# ------------------- Multivariate analysis (Both) -----------------------
def multivariate_analysis(dataframe, num_column, cat_column_1, cat_column_2):
  fig, (ax1, ax2) = plt.subplots(2, 2, figsize = (15, 7.5))

  # plot the barplor
  sns.barplot(dataframe, x = cat_column_1, y  = num_column, hue = cat_column_2, ax = ax1[0])

  # plot the boxplot
  sns.boxplot(dataframe, x = cat_column_1, y = num_column, hue = cat_column_2, gap = 0.1, ax = ax1[1])

  # plot the violin plot
  sns.violinplot(dataframe, x = cat_column_1, y = num_column, hue = cat_column_2, gap = 0.1, ax = ax2[0])

  # plot the strip plot
  sns.stripplot(dataframe, x = cat_column_1, y = num_column, hue = cat_column_2, dodge = True, ax = ax2[1])

  plt.tight_layout()
  plt.show()



# -------------------- Hypothesis testing -----------------------
def chi_2_test(dataframe, col1, col2, alpha = 0.05):
  data = (dataframe.loc[:, [col1, col2]].dropna())

  # create contingency table
  contingency_table = pd.crosstab(data[col1], data[col2])

  # perform chi-squared test
  _, p_val, _, _ = chi2_contingency(contingency_table)
  print(p_val)
  if p_val <= alpha:
    print(f"Reject the null hypothesis. There are strong connection between {col1} and {col2}.")
  else:
    print(f"Fail to reject the null hypothesis. There are no strong connection between {col1} and {col2}.")


def anova_test(dataframe, num_col, cat_col, alpha = 0.05):
  data = (dataframe.loc[:, [num_col, cat_col]].dropna())

  # create a category group
  cat_group = data.groupby(cat_col)
  groups = [group[num_col].values for _, group in cat_group]
  f_stat, p_val = f_oneway(*groups)
  print(p_val)
  if p_val <= alpha:
    print(f"Reject the null hypothesis. There are strong connection between {num_col} and {cat_col}.")
  else:
    print(f"Fail to reject the null hypothesis. There are no strong connection between {num_col} and {cat_col}.")


def test_for_normality(dataframe, column_name, alpha = 0.05):
  data = dataframe[column_name]
  print("Jarque Bera Test for Normality")
  _, p_val = jarque_bera(data)
  print(p_val)
  if p_val <= alpha:
    print(f"Reject the null hypothesis. The Data is not normally distributed")
  else:
    print(f"Fail to reject the null hypothesis. The Data is normally distributed.", end = "\n\n")

"""## Column wise analysis"""

Data.columns

"""## Time taken (Target column)"""

Data['time_taken'].dtype

# Numerical analysis of target column
numerical_analysis(Data, 'time_taken', bins = 10)

"""**Observations:**
1. The target column is not fully continuous in nature.
2. The target column shows dual mortality with two peaks:-
    - First peak around the 17-18 at a point
    - Second peak around 26-27 at a point.
3. The target column has some extreme points which can be thought of as outliers but they are just extreme and rare, not outliers. 50 min time is possible for delivery in certain rare cases.
"""

# plot QQ plot for the target

probplot(Data['time_taken'], plot = plt)
plt.show()

# Test for normality
test_for_normality(Data, 'time_taken')

# Checking the rows where data is acting as outliers
target_25_per, target_75_per = np.percentile(Data['time_taken'], [25, 75])
iqr = target_75_per - target_25_per

upper_bound = target_75_per + (1.5 * iqr)

print(upper_bound)

# Compare with traffic
Data.loc[(Data['time_taken'] > upper_bound),"traffic"].value_counts()

# Compare with weather
Data.loc[(Data['time_taken'] > upper_bound),"weather"].value_counts()

# Average distances
avg_distance = Data.loc[:, "distance"].mean()
avg_distance_extreme = Data.loc[(Data['time_taken'] > upper_bound),"distance"].mean()

print(avg_distance, avg_distance_extreme)

# Fic target column using transformation
from sklearn.preprocessing import PowerTransformer

pt = PowerTransformer(method = "yeo-johnson")

Data['time_taken_pt'] = pt.fit_transform(Data[['time_taken']])

numerical_analysis(Data, "time_taken_pt", bins = 10)

# plot QQ plot for the target after transformation

probplot(Data['time_taken_pt'], plot = plt)
plt.show()



"""## Rider_id"""

Data[['rider_id', 'age', 'ratings']]

rider_id_group = Data[['rider_id', 'age', 'ratings']].groupby('rider_id')
rider_id_group.head().sort_values('rider_id')

# Check for duplicated
Data[['rider_id', 'age', 'ratings']].dropna().duplicated(keep = False).sum()

# Filter the duplicates
Data.loc[(Data[['rider_id', 'age', 'ratings']].duplicated(keep = False)),['rider_id', 'age', 'ratings']].dropna().sort_values(['rider_id'])



"""## Age"""

Data['age'].describe()

numerical_analysis(Data, 'age', bins = 20)

# relation between target and age column
sns.scatterplot(Data, x = 'age', y = 'time_taken')

"""**Age of the rider does not show any impact on time taken to deliver.**"""

sns.scatterplot(Data, x = 'age', y = 'time_taken', hue = "vehicle_condition")
plt.legend(bbox_to_anchor = (1.02, 1), loc = 2)

# preferences of vehicle type based on age
sns.stripplot(Data, x = 'type_of_vehicle', y = 'age')



"""## Ratings"""

Data['ratings'].describe()

numerical_analysis(Data, 'ratings', bins = 5)

# Does ratings effect delivery time
sns.scatterplot(Data, x = 'ratings', y = 'time_taken')

"""**It shows that riders with more ratings get more orders.**"""

# Does ratings get affected by vehicle type

numerical_categorical_analysis(Data, 'vehicle_condition', 'ratings')

"""**Observations:**
1. The worst vehicle condition is, the more lower the ratings get.
2. The category 3 have no data means there are NaN values. This simply means that customer avoid rating their rider even rating of 1 when the vehicle condition is bad.
"""

Data[['ratings','vehicle_condition']].loc[Data['vehicle_condition'] == 3, "ratings"].value_counts(dropna = False)

# Does type of vehicle affect the ratings

numerical_categorical_analysis(Data, 'type_of_vehicle', 'ratings')

# Does festival affect the rider ratings

numerical_categorical_analysis(Data, 'festival', 'ratings')



"""## Location based features"""

Data.columns[3:7].tolist() + ["city_name"]

# location subset
location_subset = Data.loc[:,Data.columns[3:7].tolist() + ["city_name"]]

location_subset

# plot deliveries on map
delivery_df = pd.DataFrame({
    'latitude': location_subset['delivery_latitude'],
    'longitude': location_subset['delivery_longitude'],
    'city_name': location_subset['city_name']
})


# Create a map
fig = px.scatter_mapbox(delivery_df, lat = 'latitude', lon = 'longitude', title = 'Delivery Points', hover_name = 'city_name')


# Update the layout of map india
fig.update_layout(mapbox_style = 'carto-positron', mapbox_center = {"lat":20.5937, "lon":78.9629}, mapbox_zoom = 3)

fig.show()



"""## Order date"""

Data.columns

Data.filter(like = "order")

# order date columns

order_date_subset = Data.loc[:, ['order_date', 'order_day', 'order_month', 'order_day_of_week', 'is_weekend', 'festival']]

order_date_subset

# Analysis between day of week and target

numerical_categorical_analysis(Data, 'order_day_of_week', 'time_taken')

# Does weekend affect target column

numerical_categorical_analysis(Data, 'is_weekend', 'time_taken')

# Does weekend affect traffic

chi_2_test(Data, 'is_weekend', 'traffic')

# Festival and target column
numerical_categorical_analysis(Data, 'festival', 'time_taken')

"""**Observations:**
1. The avg time it takes for delivery varies when there is a festival.
2. The range of delivery time is shorter when there is a festival with lesser variation, which means on a festival delivery times usually takes longer.
"""

# Does festival affect traffic

chi_2_test(Data, 'festival', 'traffic')

Data.pivot_table(index = 'traffic', columns = 'festival', values = 'time_taken', aggfunc = 'mean')

# Does weekend and festival both features have affact on delivery times
multivariate_analysis(Data, 'time_taken', 'is_weekend', 'festival')



"""## Order time"""

Data.columns

time_subset = Data.loc[:, ['order_time_hour', 'order_time_of_day', 'pickup_time_minutes']]

time_subset

# Does times of day affects delivery times
numerical_categorical_analysis(Data, 'order_time_of_day', 'time_taken')

# Anova test
anova_test(Data, 'time_taken', 'order_time_of_day')

Data['order_time_hour'].value_counts().head()

categorical_analysis(Data, 'order_time_hour')



"""## Pickup time"""

# Relationship between pickup time and delivery time
sns.scatterplot(Data, x = 'pickup_time_minutes', y = 'time_taken')

categorical_analysis(Data, 'pickup_time_minutes')

numerical_categorical_analysis(Data, 'pickup_time_minutes', 'time_taken')

anova_test(Data, 'time_taken', 'pickup_time_minutes')



"""## Traffic"""

categorical_analysis(Data, 'traffic')

chi_2_test(Data, 'traffic', 'city_type')

chi_2_test(Data, 'traffic', 'city_name')

numerical_categorical_analysis(Data, 'traffic', 'time_taken')

anova_test(Data, 'time_taken', 'traffic')

multivariate_analysis(Data, 'time_taken', 'traffic', 'type_of_vehicle')

multivariate_analysis(Data, 'time_taken', 'traffic', 'vehicle_condition')



"""## Multiple deliveries"""

numerical_categorical_analysis(Data, 'multiple_deliveries', 'time_taken')

anova_test(Data, 'time_taken', 'multiple_deliveries')

numerical_categorical_analysis(Data, 'multiple_deliveries', 'distance')



"""## Weather"""

categorical_analysis(Data, 'weather')

numerical_categorical_analysis(Data, 'weather', 'time_taken')

anova_test(Data, 'time_taken', 'weather')

chi_2_test(Data, 'weather', 'traffic')

multivariate_analysis(Data, 'time_taken', 'weather', 'traffic')

Data.pivot_table(index = 'weather', columns = 'traffic', values = 'time_taken', aggfunc = 'mean')



"""## Vehicle condition and type"""

categorical_analysis(Data, 'vehicle_condition')

numerical_categorical_analysis(Data, 'vehicle_condition', 'time_taken')

anova_test(Data, 'time_taken', 'vehicle_condition')

categorical_analysis(Data, 'type_of_vehicle')

numerical_categorical_analysis(Data, 'type_of_vehicle', 'time_taken')

multivariate_analysis(Data, 'time_taken', 'vehicle_condition', 'type_of_vehicle')

chi_2_test(Data, 'type_of_vehicle', 'vehicle_condition')



"""## Type of order"""

categorical_analysis(Data, 'type_of_order')

numerical_categorical_analysis(Data, 'type_of_order', 'time_taken')

anova_test(Data, 'time_taken', 'type_of_order')

pd.crosstab(Data['type_of_order'], Data['is_weekend'])

chi_2_test(Data, 'pickup_time_minutes', 'type_of_order')

numerical_categorical_analysis(Data, 'type_of_order', 'ratings')

chi_2_test(Data, 'is_weekend', 'type_of_order')

chi_2_test(Data, 'festival', 'type_of_order')



"""## City name"""

categorical_analysis(Data, 'city_name')

numerical_categorical_analysis(Data, 'city_type', 'time_taken')

anova_test(Data, 'time_taken', 'city_type')

numerical_categorical_analysis(Data, 'city_type', 'ratings')

multivariate_analysis(Data, 'time_taken', 'city_type', 'type_of_vehicle')



"""## Distance"""

numerical_analysis(Data, 'distance', bins = 10)

sns.scatterplot(Data, x = 'distance', y = 'time_taken')

# correlation
Data[['distance', 'time_taken']].corr()

numerical_categorical_analysis(Data, 'type_of_vehicle', 'distance')

numerical_categorical_analysis(Data, 'festival', 'distance')