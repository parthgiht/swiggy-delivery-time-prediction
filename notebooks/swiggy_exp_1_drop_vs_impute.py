# -*- coding: utf-8 -*-
"""Swiggy_Exp-1_drop_vs_impute.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1guFquYTyJIevFkLv9AEYBPzE__IPvn7h
"""

import pandas as pd
import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer, KNNImputer, MissingIndicator
from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder, MinMaxScaler, PowerTransformer, OrdinalEncoder
from sklearn.model_selection import train_test_split

# Commented out IPython magic to ensure Python compatibility.
# %pip install mlflow dagshub

import dagshub
dagshub.init(repo_owner = "parthgiht", repo_name = "swiggy-delivery-time-prediction", mlflow = True)

from sklearn import set_config
set_config(transform_output = "pandas")

"""## Load data"""

Data = pd.read_csv('/content/swiggy_cleaned.csv')
Data.head()

Data['distance_type'] = pd.cut(
    Data['distance'],
    bins=[0, 5, 10, 15, 25],
    right=False,
    labels=['short', 'medium', 'long', 'very_long']
)

# Drop that columns which are not helpful for model input
columns_to_drop = [
    'rider_id',
    'restaurant_latitude',
    'restaurant_longitude',
    'delivery_latitude',
    'delivery_longitude',
    'order_date',
    'order_time_hour',
    'order_day',
    'city_name',
    'order_day_of_week',
    'order_month'
]

Data.drop(columns = columns_to_drop, inplace = True)

Data.head()

Data.shape

# Check null values

Data.isnull().sum()

Data.info()

# Check duplicates
print(Data.duplicated().sum())

import missingno as msno

msno.matrix(Data)

Data['order_time_of_day'].isna().sum()

# Columns that have missing values
missing_cols = Data.isna().any(axis = 0).loc[lambda x:x].index

missing_cols

"""## Drop missing values"""

import mlflow

# Set the tracking uri
mlflow.set_tracking_uri('https://dagshub.com/parthgiht/swiggy-delivery-time-prediction.mlflow')

# Set the experiment
mlflow.set_experiment("Exp 1 - Keep vs Drop missing values")

temp_df = Data.copy().dropna()

temp_df

# Split in to X and y
X = temp_df.drop(columns = ['time_taken'])
y = temp_df['time_taken']

X.shape

y.shape

# train test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

X_train

y_train

X_test

y_test

# Missing in training data
X_train.isna().sum()

X_train.columns

len(X_train.columns )

# Do basic preprocessing
Num_cols = ['age', 'ratings', 'pickup_time_minutes', 'distance']
Nominal_cat_cols = ['weather', 'type_of_order', 'type_of_vehicle', 'festival', 'city_type', 'is_weekend', 'order_time_of_day']
Ordinal_cat_cols = ['traffic', 'distance_type']

# generate order for ordinal encoding

traffic_order = ["low","medium","high","jam"]

distance_type_order = ["short","medium","long","very_long"]

# build a preprocessor
preprocessor = ColumnTransformer(transformers = [
    ('Scale', MinMaxScaler(), Num_cols),
    ('Nominal_encode', OneHotEncoder(drop = 'first', handle_unknown = 'ignore', sparse_output = False), Nominal_cat_cols),
    ('Ordinal_encode', OrdinalEncoder(categories = [traffic_order, distance_type_order]), Ordinal_cat_cols)
], remainder = 'passthrough', n_jobs = -1, force_int_remainder_cols = False, verbose_feature_names_out = False)

preprocessor.set_output(transform = 'pandas')

# Transform the data
X_train_trans = preprocessor.fit_transform(X_train)
X_test_trans = preprocessor.transform(X_test)

X_train_trans

X_test_trans

# Transform the target column
pt = PowerTransformer()

y_train_pt  = pt.fit_transform(y_train.values.reshape(-1, 1))
y_test_pt = pt.transform(y_test.values.reshape(-1, 1))

pt.lambdas_

y_train_pt

y_train_pt

from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(n_estimators = 100, random_state = 42)

rf.fit(X_train_trans, y_train_pt.values.ravel())

# get the predictions
y_pred_train = rf.predict(X_train_trans)
y_pred_test = rf.predict(X_test_trans)

# get the actual predicitons values
y_pred_train_org = pt.inverse_transform(y_pred_train.reshape(-1, 1))
y_pred_test_org = pt.inverse_transform(y_pred_test.reshape(-1, 1))

from sklearn.metrics import mean_absolute_error, r2_score

print(f'Train error is {mean_absolute_error(y_train, y_pred_train_org):.2f} minutes')
print(f'Test error is {mean_absolute_error(y_test, y_pred_test_org):.2f} minutes')

print(f'Train r2_score is {r2_score(y_train, y_pred_train_org):.2f}')
print(f'Test r2_score is {r2_score(y_test, y_pred_test_org):.2f}')

# Calculate the cross val score
from sklearn.model_selection import cross_val_score

scores = cross_val_score(rf, X_train_trans, y_train_pt.values.ravel(), cv = 5, scoring = 'r2', n_jobs = -1)

scores

# mean score
print(scores.mean())

# features importance plot
feat_imp = pd.DataFrame(
    rf.feature_importances_,
    index=X_train_trans.columns,
    columns=["importance"]
)

feat_imp.sort_values(by="importance").plot(kind="barh", figsize=(10, 10))

# Log experiment
with mlflow.start_run(run_name = "Drop missing values"):
  mlflow.log_param("Experiment_type", "Drop missing values")
  mlflow.log_params(rf.get_params())

  # log metrics
  mlflow.log_metric("training_error",mean_absolute_error(y_train, y_pred_train_org))
  mlflow.log_metric("test_error",mean_absolute_error(y_test, y_pred_test_org))
  mlflow.log_metric("training_r2",r2_score(y_train, y_pred_train_org))
  mlflow.log_metric("test_r2",r2_score(y_test, y_pred_test_org))
  mlflow.log_metric("cross_val",scores.mean())

from sklearn.feature_selection import RFECV

rfecv = RFECV(
    estimator = rf,
    step = 10,
    cv = 5,
    scoring = 'r2',
    n_jobs= -1,
    verbose = 2
)

# select features
rfecv.fit(X_train_trans, y_train_pt.values.ravel())

# list of selected features
rfecv.get_feature_names_out()

from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor()

rf.fit(rfecv.transform(X_train_trans), y_train_pt.values.ravel())

# get the predictions
y_pred_train = rf.predict(rfecv.transform(X_train_trans))
y_pred_test = rf.predict(rfecv.transform(X_test_trans))

# get the actual predicitons values
y_pred_train_org = pt.inverse_transform(y_pred_train.reshape(-1, 1))
y_pred_test_org = pt.inverse_transform(y_pred_test.reshape(-1, 1))

from sklearn.metrics import mean_absolute_error, r2_score

print(f'Train error is {mean_absolute_error(y_train, y_pred_train_org):.2f} minutes')
print(f'Test error is {mean_absolute_error(y_test, y_pred_test_org):.2f} minutes')

print(f'Train r2_score is {r2_score(y_train, y_pred_train_org):.2f}')
print(f'Test r2_score is {r2_score(y_test, y_pred_test_org):.2f}')

# Calculate the cross val score
from sklearn.model_selection import cross_val_score

scores = cross_val_score(rf, rfecv.transform(X_train_trans), y_train_pt.values.ravel(), cv = 5, scoring = 'r2', n_jobs = -1)

scores

# scores mean
print(scores.mean())

rf.feature_importances_

# features importance plot
# features importance plot
feat_imp = pd.DataFrame(
    rf.feature_importances_,
    index=rfecv.transform(X_train_trans).columns,
    columns=["importance"]
)

feat_imp.sort_values(by="importance").plot(kind="barh", figsize=(10, 10))



"""## Impute missing values"""

temp_df = Data.copy()

X = temp_df.drop(columns = ['time_taken'])
y = temp_df['time_taken']

X

y

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

X_train.isna().sum()

# Transform the target column
pt = PowerTransformer()

y_train_pt  = pt.fit_transform(y_train.values.reshape(-1, 1))
y_test_pt = pt.transform(y_test.values.reshape(-1, 1))

missing_cols

# percentage of rows in data having missing values
X_train.isna().any(axis = 1).mean().round(2)

"""## Imputation pipeline"""

Nominal_cat_cols

X_train.isna().sum()

# features to fill values with mode value
features_to_fill_mode = ['multiple_deliveries', 'festival', 'city_type']

features_to_fill_missing = [col for col in Nominal_cat_cols if col not in features_to_fill_mode]

features_to_fill_missing

# Simple imputer to fill categorical vars with mode
simple_imputer = ColumnTransformer(transformers= [
    ('mode_imputer', SimpleImputer(strategy = 'most_frequent'), features_to_fill_mode),
    ('missing_imputer', SimpleImputer(strategy = 'constant', fill_value = 'missing'), features_to_fill_missing)
], remainder = 'passthrough', n_jobs = -1, force_int_remainder_cols = False, verbose_feature_names_out = False)

simple_imputer

simple_imputer.fit_transform(X_train)

simple_imputer.fit_transform(X_train).isna().sum()

# KNN imputer

KNN_imputer = KNNImputer(n_neighbors = 5)

# Do basic preprocessing
Num_cols = ['age', 'ratings', 'pickup_time_minutes', 'distance']
Nominal_cat_cols = ['weather', 'type_of_order', 'type_of_vehicle', 'festival', 'city_type', 'is_weekend', 'order_time_of_day']
Ordinal_cat_cols = ['traffic', 'distance_type']

# generate order for ordinal encoding

traffic_order = ["low","medium","high","jam"]

distance_type_order = ["short","medium","long","very_long"]

# build a preprocessor
preprocessor = ColumnTransformer(transformers = [
    ('Scale', MinMaxScaler(), Num_cols),
    ('Nominal_encode', OneHotEncoder(drop = 'first', handle_unknown = 'ignore', sparse_output = False), Nominal_cat_cols),
    ('Ordinal_encode', OrdinalEncoder(categories = [traffic_order, distance_type_order], encoded_missing_value = -999, handle_unknown = 'use_encoded_value', unknown_value = -1), Ordinal_cat_cols)
], remainder = 'passthrough', n_jobs = -1, force_int_remainder_cols = False, verbose_feature_names_out = False)

preprocessor

preprocessor.fit_transform(X_train)

preprocessor.fit_transform(X_train).isna().sum().loc[lambda ser: ser.ge(1)]

# build the pipeline
processing_pipeline = Pipeline(steps = [
    ('simple_imputer', simple_imputer),
    ('preprocess',preprocessor),
    ('knn_imputer',KNN_imputer)
])

processing_pipeline

model_pipe = Pipeline(steps = [
    ('preprocessing', processing_pipeline),
    ('model',rf)
])

model_pipe

# fit the pipeline on data
model_pipe.fit(X_train, y_train_pt.values.ravel())

# get the predictions
y_pred_train = model_pipe.predict(X_train)
y_pred_test = model_pipe.predict(X_test)

# get the actual predicitons values
y_pred_train_org = pt.inverse_transform(y_pred_train.reshape(-1, 1))
y_pred_test_org = pt.inverse_transform(y_pred_test.reshape(-1, 1))

from sklearn.metrics import mean_absolute_error, r2_score

print(f'Train error is {mean_absolute_error(y_train, y_pred_train_org):.2f} minutes')
print(f'Test error is {mean_absolute_error(y_test, y_pred_test_org):.2f} minutes')

print(f'Train r2_score is {r2_score(y_train, y_pred_train_org):.2f}')
print(f'Test r2_score is {r2_score(y_test, y_pred_test_org):.2f}')

# Calculate the cross val score
from sklearn.model_selection import cross_val_score

scores = cross_val_score(model_pipe, X_train, y_train_pt.values.ravel(), cv = 5, scoring = 'r2', n_jobs = -1)

scores

# mean score
scores.mean()

# Log experiment
with mlflow.start_run(run_name = "Impute missing values"):
  mlflow.log_param("Experiment_type", "Impute missing values")
  mlflow.log_params(rf.get_params())

  # log metrics
  mlflow.log_metric("training_error",mean_absolute_error(y_train, y_pred_train_org))
  mlflow.log_metric("test_error",mean_absolute_error(y_test, y_pred_test_org))
  mlflow.log_metric("training_r2",r2_score(y_train, y_pred_train_org))
  mlflow.log_metric("test_r2",r2_score(y_test, y_pred_test_org))
  mlflow.log_metric("cross_val",scores.mean())

